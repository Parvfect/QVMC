{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "340a0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3404a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor([0.0], requires_grad=True)\n",
    "x2 = torch.tensor([0.3], requires_grad=True)\n",
    "x3 = torch.tensor([0.4], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "910e7748",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = torch.tensor([0.1], requires_grad=True)\n",
    "y2 = torch.tensor([-0.3], requires_grad=True)\n",
    "y3 = torch.tensor([0.2], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1684ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([x1, x2, x3])\n",
    "y = torch.tensor([y1, y2, y3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8c5ef69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = torch.linalg.norm(x)\n",
    "r2 = torch.linalg.norm(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2302b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r12 = torch.linalg.norm(x - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82f50f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_1 = torch.tensor([1.013], requires_grad=True)\n",
    "alpha_2 = torch.tensor([0.2119], requires_grad=True)\n",
    "alpha_3 = torch.tensor([0.1406], requires_grad=True)\n",
    "alpha_4 = torch.tensor([0.003], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "583c2ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = torch.e ** (-2 * (r1 + r2)) * (1 + 0.5 * r12 * torch.e ** (-alpha_1 * r12)) * (1 + alpha_2 * (r1 + r2) * r12 + alpha_3 * (r1 - r2) ** 2 - alpha_4 * r12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "203d5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2bd0c604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1013b55",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m second_derivative \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_derivative\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_unused \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    351\u001b[0m     allow_unused \u001b[38;5;241m=\u001b[39m materialize_grads\n\u001b[0;32m    352\u001b[0m t_outputs \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m    353\u001b[0m     Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m--> 354\u001b[0m     (outputs,) \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(outputs) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(inputs) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, graph\u001b[38;5;241m.\u001b[39mGradientEdge):\n\u001b[0;32m    357\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m cast(_TensorOrTensorsOrGradEdge, (inputs,))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "second_derivative = torch.autograd.grad(first_derivative[0], x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1e7fe4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from autograd import elementwise_grad as egrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "77aa5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.2, 0.3, 0.1])\n",
    "y = np.array([0.1, 0.4, 0.3])\n",
    "r1 = np.linalg.norm(x)\n",
    "r2 = np.linalg.norm(y)\n",
    "r12 = np.linalg.norm(x - y)\n",
    "alpha_1 = 1.013\n",
    "alpha_2 = 0.2119\n",
    "alpha_3 = 0.1406\n",
    "alpha_4 = 0.003\n",
    "\n",
    "def psi(x, y, alpha_1, alpha_2, alpha_3, alpha_4):\n",
    "    r1 = np.linalg.norm(x)\n",
    "    r2 = np.linalg.norm(y)\n",
    "    r12 = np.linalg.norm(x - y)\n",
    "\n",
    "    return np.e ** (-2 * (r1 + r2)) * (1 + 0.5 * r12 * np.e ** (-alpha_1 * r12)) * (1 + alpha_2 * (r1 + r2) * r12 + alpha_3 * (r1 - r2) ** 2 - alpha_4 * r12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0c236b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define constants\n",
    "alpha_1 = 1.013\n",
    "alpha_2 = 0.2119\n",
    "alpha_3 = 0.1406\n",
    "alpha_4 = 0.003\n",
    "\n",
    "# Define psi using torch\n",
    "def psi(x, y):\n",
    "    r1 = torch.norm(x)\n",
    "    r2 = torch.norm(y)\n",
    "    r12 = torch.norm(x - y)\n",
    "\n",
    "    term1 = torch.exp(-2 * (r1 + r2))\n",
    "    term2 = 1 + 0.5 * r12 * torch.exp(-alpha_1 * r12)\n",
    "    term3 = 1 + alpha_2 * (r1 + r2) * r12 + alpha_3 * (r1 - r2)**2 - alpha_4 * r12\n",
    "\n",
    "    return term1 * term2 * term3\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "x = torch.tensor([0.2, 0.3, 0.1], dtype=torch.float64, requires_grad=True)\n",
    "y = torch.tensor([0.1, 0.4, 0.3], dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "# Compute psi\n",
    "psi_val = psi(x, y)\n",
    "\n",
    "# Compute gradients (first derivatives)\n",
    "grad_x, grad_y = torch.autograd.grad(psi_val, (x, y), create_graph=True)\n",
    "\n",
    "# Compute second derivatives\n",
    "# For example: second derivative of psi with respect to x[0] and x[1]\n",
    "d2psi_dx0dx1 = torch.autograd.grad(grad_x[0], x, retain_graph=True)[0][1]  # ∂²ψ/∂x₀∂x₁\n",
    "\n",
    "# You can construct the full Hessian for x or y like this:\n",
    "def hessian(grad_vec, vars):\n",
    "    return torch.stack([torch.autograd.grad(g, vars, retain_graph=True)[0] for g in grad_vec])\n",
    "\n",
    "hess_x = hessian(grad_x, x)  # 3x3 Hessian wrt x\n",
    "hess_y = hessian(grad_y, y)  # 3x3 Hessian wrt y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "43bd21aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplacian with respect to x: -0.5628513385054579\n",
      "Laplacian with respect to y: -0.28447621380463595\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Constants\n",
    "alpha_1 = 1.013\n",
    "alpha_2 = 0.2119\n",
    "alpha_3 = 0.1406\n",
    "alpha_4 = 0.003\n",
    "\n",
    "# psi function using torch\n",
    "def psi(x, y):\n",
    "    r1 = torch.norm(x)\n",
    "    r2 = torch.norm(y)\n",
    "    r12 = torch.norm(x - y)\n",
    "\n",
    "    term1 = torch.exp(-2 * (r1 + r2))\n",
    "    term2 = 1 + 0.5 * r12 * torch.exp(-alpha_1 * r12)\n",
    "    term3 = 1 + alpha_2 * (r1 + r2) * r12 + alpha_3 * (r1 - r2)**2 - alpha_4 * r12\n",
    "\n",
    "    return term1 * term2 * term3\n",
    "\n",
    "# Tensors with gradients enabled\n",
    "x = torch.tensor([0.2, 0.3, 0.1], dtype=torch.float64, requires_grad=True)\n",
    "y = torch.tensor([0.1, 0.4, 0.3], dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "# Compute psi\n",
    "psi_val = psi(x, y)\n",
    "\n",
    "# First gradients\n",
    "grad_x = torch.autograd.grad(psi_val, x, create_graph=True)[0]\n",
    "grad_y = torch.autograd.grad(psi_val, y, create_graph=True)[0]\n",
    "\n",
    "# Laplacian with respect to x\n",
    "laplacian_x = sum(torch.autograd.grad(grad_x[i], x, retain_graph=True)[0][i] for i in range(3))\n",
    "\n",
    "# Laplacian with respect to y\n",
    "laplacian_y = sum(torch.autograd.grad(grad_y[i], y, retain_graph=True)[0][i] for i in range(3))\n",
    "\n",
    "print(\"Laplacian with respect to x:\", laplacian_x.item())\n",
    "print(\"Laplacian with respect to y:\", laplacian_y.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e99d2788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(-0.5851, dtype=torch.float64), tensor(2.5131, dtype=torch.float64), tensor(0.6771, dtype=torch.float64), tensor(-2.5998, dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define alphas as torch tensors with requires_grad=True\n",
    "alpha_1 = torch.tensor(1.013, dtype=torch.float64, requires_grad=True)\n",
    "alpha_2 = torch.tensor(0.2119, dtype=torch.float64, requires_grad=True)\n",
    "alpha_3 = torch.tensor(0.1406, dtype=torch.float64, requires_grad=True)\n",
    "alpha_4 = torch.tensor(0.003, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "alphas = [alpha_1, alpha_2, alpha_3, alpha_4]\n",
    "\n",
    "# psi function using torch\n",
    "def psi(x, y, alpha_1, alpha_2, alpha_3, alpha_4):\n",
    "    r1 = torch.norm(x)\n",
    "    r2 = torch.norm(y)\n",
    "    r12 = torch.norm(x - y)\n",
    "\n",
    "    term1 = torch.exp(-2 * (r1 + r2))\n",
    "    term2 = 1 + 0.5 * r12 * torch.exp(-alpha_1 * r12)\n",
    "    term3 = 1 + alpha_2 * (r1 + r2) * r12 + alpha_3 * (r1 - r2)**2 - alpha_4 * r12\n",
    "\n",
    "    return term1 * term2 * term3\n",
    "\n",
    "# Tensors with gradients enabled\n",
    "x = torch.tensor([0.2, 0.3, 0.1], dtype=torch.float64, requires_grad=True)\n",
    "y = torch.tensor([0.1, 0.4, 0.3], dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "# Compute psi\n",
    "psi_val = psi(x, y, *alphas)\n",
    "\n",
    "# First gradients w.r.t. x and y\n",
    "grad_x = torch.autograd.grad(psi_val, x, create_graph=True)[0]\n",
    "grad_y = torch.autograd.grad(psi_val, y, create_graph=True)[0]\n",
    "\n",
    "# Laplacians\n",
    "laplacian_x = sum(torch.autograd.grad(grad_x[i], x, retain_graph=True, create_graph=True)[0][i] for i in range(3))\n",
    "laplacian_y = sum(torch.autograd.grad(grad_y[i], y, retain_graph=True, create_graph=True)[0][i] for i in range(3))\n",
    "\n",
    "lap = laplacian_x + laplacian_y\n",
    "# Derivatives of Laplacians w.r.t. alphas\n",
    "dlap_dalpha = torch.autograd.grad(lap, alphas, retain_graph=True)\n",
    "\n",
    "\n",
    "print(dlap_dalpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6caa9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I just need to add the PE and then we are golden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3dd32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
