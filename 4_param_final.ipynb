{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31561eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from analytical_expressions import local_energy\n",
    "from torch.autograd.functional import jacobian\n",
    "from torch.func import jacrev\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.func import vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "1012fd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06526d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(X):\n",
    "    x = X[:3]\n",
    "    y = X[3:6]\n",
    "    alpha_1, alpha_2, alpha_3, alpha_4 = X[6:]\n",
    "    r1 = torch.norm(x)\n",
    "    r2 = torch.norm(y)\n",
    "    r12 = torch.norm(x - y)\n",
    "\n",
    "    term1 = torch.exp(-2 * (r1 + r2))\n",
    "    term2 = 1 + 0.5 * r12 * torch.exp(-alpha_1 * r12)\n",
    "    term3 = 1 + alpha_2 * (r1 + r2) * r12 + alpha_3 * (r1 - r2)**2 - alpha_4 * r12\n",
    "\n",
    "    return term1 * term2 * term3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0704f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_vec = vmap(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a509ef40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0019, 0.3977, 0.3567])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d6f7a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis(N: int, n_runs: int, alphas: torch.tensor):  \n",
    "    \"\"\"\n",
    "    Vectorized metropolis loop\n",
    "    Over N steps, for n_runs. \n",
    "    Alphas passes in must be of same dim as n_runs\n",
    "    \"\"\"  \n",
    "    assert alphas.shape[0] == n_runs        \n",
    "    L = 1\n",
    "    r1 = (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "    r2 = (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "    max_steps = 500\n",
    "    sampled_Xs = []\n",
    "    rejection_ratio = 0\n",
    "\n",
    "    for i in tqdm(range(N)):\n",
    "        chose = torch.rand(n_runs).reshape(n_runs, 1)\n",
    "        dummy = torch.rand(n_runs)\n",
    "\n",
    "        perturbed_r1 = r1 + 0.5 * (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "        perturbed_r2 = r2 + 0.5 * (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "\n",
    "        r1_trial = torch.where(chose < 0.5, perturbed_r1, r1)\n",
    "        r2_trial = torch.where(chose >= 0.5, perturbed_r2, r2)\n",
    "        psi_val = psi_vec(torch.cat((r1, r2, alphas), axis=1))\n",
    "        psi_trial_val = psi_vec(torch.cat((r1_trial, r2_trial, alphas), axis=1))      \n",
    "        psi_ratio = psi_trial_val / psi_val\n",
    "\n",
    "        density_comp = psi_trial_val >= psi_val\n",
    "        dummy_comp = dummy < psi_ratio\n",
    "\n",
    "        condition = density_comp + dummy_comp\n",
    "\n",
    "        rejection_ratio += torch.where(condition, 1./N, 0.0)\n",
    "\n",
    "        condition = condition.reshape(condition.shape[0], 1)\n",
    "\n",
    "        # Careful with overwriting\n",
    "        r1 = torch.where(condition, r1_trial, r1)\n",
    "        r2 = torch.where(condition, r2_trial, r2)\n",
    "                \n",
    "        if i > max_steps:\n",
    "            sampled_Xs.append(torch.cat((r1, r2, alphas), axis=1))\n",
    "\n",
    "    print(f\"Rejection ratio is {torch.mean(rejection_ratio)}\")\n",
    "\n",
    "    return torch.stack(sampled_Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "81121059",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_e_vec = vmap(local_energy)\n",
    "local_e_vec_vec = vmap(local_e_vec)\n",
    "\n",
    "def get_local_energies(X):\n",
    "    reshaped_X = X.reshape(\n",
    "        X.shape[1], X.shape[0], X.shape[2])\n",
    "    return local_e_vec_vec(reshaped_X)\n",
    "\n",
    "def get_mean_energies(E):\n",
    "    return torch.mean(torch.mean(E, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f9a30834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dE_dalpha(input):\n",
    "    return jacrev(local_energy)(input)\n",
    "\n",
    "dE_dalpha_vec = vmap(dE_dalpha)\n",
    "dE_dalpha_vec_vec = vmap(dE_dalpha_vec)\n",
    "\n",
    "def get_dE_dX(X):\n",
    "    reshaped_X = X.reshape(\n",
    "        X.shape[1], X.shape[0], X.shape[2])\n",
    "    return dE_dalpha_vec_vec(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "93c28601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_expressions import get_psi_alpha\n",
    "\n",
    "def get_gradients_from_expression(X_, E_):\n",
    "    psi_alpha = vmap(get_psi_alpha)(X_)\n",
    "\n",
    "    part_1 = psi_alpha - torch.mean(psi_alpha, axis=0)\n",
    "    part_2 = E_ - torch.mean(E_)\n",
    "    return torch.mean(part_1.T * part_2, axis=1)\n",
    "\n",
    "dE_dalpha = vmap(get_gradients_from_expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ac777f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_1 = torch.tensor(1.013, dtype=torch.float64, requires_grad=True) # 1.013\n",
    "alpha_2 = torch.tensor(0.2119, dtype=torch.float64, requires_grad=True)\n",
    "alpha_3 = torch.tensor(0.1406, dtype=torch.float64, requires_grad=True)\n",
    "alpha_4 = torch.tensor(0.003, dtype=torch.float64, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d5bf74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "274bb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_average(tensor, window_size=None):\n",
    "    cumsum = torch.cumsum(tensor, dim=0)\n",
    "    if window_size is None:\n",
    "        # For the full running average (over all elements)\n",
    "        return cumsum / torch.arange(1, len(tensor) + 1, device=tensor.device, dtype=torch.float32)\n",
    "    else:\n",
    "        # For a moving average with a fixed window size\n",
    "        window = torch.ones(window_size, device=tensor.device)\n",
    "        conv = torch.conv1d(tensor.unsqueeze(0).unsqueeze(0), window.unsqueeze(0).unsqueeze(0), padding=window_size//2)\n",
    "        return conv.squeeze(0).squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15d5d9",
   "metadata": {},
   "source": [
    "## Start of simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0ef97886",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_1 = torch.tensor(1.013, dtype=torch.float64) # 1.013\n",
    "alpha_2 = torch.tensor(0.2119, dtype=torch.float64)\n",
    "alpha_3 = torch.tensor(0.1406, dtype=torch.float64)\n",
    "alpha_4 = torch.tensor(0.003, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0cebb066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.25793396445032235, -0.7848700775648312, 1.1531981456196378, -0.04541513347032762\n",
    "alpha_1 = torch.tensor(0.257933, dtype=torch.float64) # 1.013\n",
    "alpha_2 = torch.sigmoid(torch.tensor(-0.78487, dtype=torch.float64))\n",
    "alpha_3 = torch.tensor(1.1531, dtype=torch.float64)\n",
    "alpha_4 = torch.sigmoid(torch.tensor(-0.0454, dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b58d1625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2579, dtype=torch.float64)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "6b232e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:08<00:00, 1142.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejection ratio is 0.7994472980499268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_steps = 100\n",
    "mc_steps = 10000\n",
    "alphas = torch.tensor([alpha_1, alpha_2, alpha_3, alpha_4]).unsqueeze(0).repeat(n_steps, 1)\n",
    "sampled_Xs = metropolis(mc_steps, n_steps, alphas=alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "ba9afae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean energy is -3.067813110225438\n"
     ]
    }
   ],
   "source": [
    "E = get_local_energies(sampled_Xs.to(device))\n",
    "mean_E = get_mean_energies(E.to(cpu))\n",
    "print(f\"Mean energy is {torch.mean(torch.mean(E, axis=1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "1a294c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = E.to(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "d4147e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_X = sampled_Xs.reshape(\n",
    "        sampled_Xs.shape[1], sampled_Xs.shape[0], sampled_Xs.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1993ed21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 9499, 10])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "1d36c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy(X):\n",
    "    X.requires_grad_(True)\n",
    "    psi_val = psi(X)\n",
    "\n",
    "    # First gradient\n",
    "    grad = torch.autograd.grad(psi_val, X, create_graph=True)[0]\n",
    "\n",
    "    # Laplacian = sum of second derivatives\n",
    "    laplacian = 0.0\n",
    "    for i in range(X.shape[0]):\n",
    "        second_deriv = torch.autograd.grad(grad[i], X, create_graph=True)[0][i]\n",
    "        laplacian += second_deriv\n",
    "\n",
    "    ke = -0.5 * laplacian / psi_val\n",
    "\n",
    "    r1 = X[:3]\n",
    "    r2 = X[3:6]\n",
    "    potential = -2 / torch.norm(r1) - 2 / torch.norm(r2) + 1 / torch.norm(r1 - r2)\n",
    "\n",
    "    return ke + potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "28d6bc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 9499, 10])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f8b749fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9499/9499 [02:06<00:00, 75.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Verifying local energy using Hessian\n",
    "E_es = []\n",
    "\n",
    "for i in tqdm(reshaped_X[0]):\n",
    "    E_es.append(get_energy(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "157022ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-3.8113, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3623, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0609, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9455, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-14.5549, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.5431, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1197, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8440, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4451, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6506, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-1.8323, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-14.1277, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1985, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0003, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8785, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3115, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1546, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6793, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3361, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4808, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0861, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0902, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-12.9443, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2508, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.5830, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9590, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8063, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4750, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8936, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.7714, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.3701, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7510, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.8646, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1476, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.2111, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2841, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5779, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8418, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(1.4201, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4690, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8973, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8255, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3091, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.9321, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6684, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3943, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7118, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9961, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7784, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.9076, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9603, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0061, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7921, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4845, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.0531, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4976, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6772, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6084, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4647, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4165, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7353, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9794, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3043, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9760, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1082, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.2074, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0183, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4356, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0768, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.2760, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.5489, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.0878, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6355, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7252, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8926, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2281, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.5996, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.3653, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1611, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-1.0033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3164, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.5269, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0296, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8088, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2516, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4990, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1459, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5831, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1945, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3600, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9889, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.7209, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0750, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6603, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1847, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2393, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4969, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1920, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.2081, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5967, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-15.0261, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.5431, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5069, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8440, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2230, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6346, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-1.8323, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-13.6817, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1985, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6532, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8471, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0804, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2442, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.2604, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5733, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4808, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7610, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0902, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-12.4032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9872, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.5194, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7920, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8278, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2631, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9374, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.5845, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.8033, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7510, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.8646, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9422, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.2173, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3121, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5779, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8418, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.7459, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6252, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2478, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.2492, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1225, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9720, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.0507, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6684, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.2219, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6224, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3708, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6935, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-9.4214, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.2216, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1100, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5856, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9628, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.0531, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0201, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6772, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6620, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7231, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7152, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7937, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4790, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9239, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5878, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5330, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.5754, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1973, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9637, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0768, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.6504, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.2575, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.1121, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.5050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6680, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3086, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2281, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2665, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.1717, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0512, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.1513, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5399, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.5269, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3356, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8088, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1032, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4990, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1131, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1294, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9278, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4910, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8774, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.1795, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6603, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5148, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3040, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2242, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2842, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.4477, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1920, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4956, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7296, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-14.7951, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.9220, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.2797, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3410, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6346, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.9345, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1380, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-14.0296, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1985, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6479, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.7710, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2590, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.2604, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7834, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7610, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5552, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-12.3031, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3393, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8871, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0557, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8278, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4460, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4383, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3260, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.4084, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8038, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.3187, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9112, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7853, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1722, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5705, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5498, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.4819, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6252, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3949, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.7689, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0768, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9720, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.5485, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4954, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3728, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6224, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4625, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6935, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.4966, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.2216, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3311, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8896, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9628, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.7643, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3928, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6772, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6620, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6564, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7152, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8332, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2535, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8285, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5848, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2256, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.5754, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2584, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0152, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2592, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.8407, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.8002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.9356, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.5448, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0167, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3489, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2281, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1410, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4376, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.2408, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6583, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5399, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.6222, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3356, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8088, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1814, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.2856, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0852, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1686, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.8035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4981, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7777, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.6144, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0086, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2452, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1925, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1886, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.7900, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.4477, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4133, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0465, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4391, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-14.3559, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.4149, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4721, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3208, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1647, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6346, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.9345, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8902, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-14.0296, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3534, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8270, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7479, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0298, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6874, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.9800, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8575, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5985, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1289, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1752, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-12.4997, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5166, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9904, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0557, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.4631, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4460, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4464, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3851, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.6847, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9644, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.5726, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1853, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3425, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1615, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8630, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7255, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9514, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8236, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1983, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.2811, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0712, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9294, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.5485, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4954, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6309, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6224, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0558, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5776, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.5337, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.2216, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2699, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5611, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9628, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.0094, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3709, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2486, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4620, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6564, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4124, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1815, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1591, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8285, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7819, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1704, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.7237, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0860, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3057, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2592, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.3568, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(8.3174, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.6264, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.5448, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0167, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1627, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.9480, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1731, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.9497, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3259, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7272, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4660, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.4152, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.9019, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3506, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4328, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.3622, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0553, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7901, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0121, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3569, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0415, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.6611, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1010, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0086, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8860, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1189, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2639, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2599, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.4833, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8282, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1603, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4331, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-14.3559, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2774, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4131, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5223, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.6919, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0365, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0300, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8410, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-13.8990, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0995, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4696, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6055, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3036, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6874, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6647, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9790, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3590, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4997, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1987, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-12.4997, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.2255, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1329, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9142, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.3768, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.8022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7846, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3727, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.6619, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9644, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.5726, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1578, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6747, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2427, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9913, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9158, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8236, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4884, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6273, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1087, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1582, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.5485, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8375, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6309, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5577, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5195, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2755, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-9.4190, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.2216, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2699, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5611, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5873, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.6838, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3338, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2486, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3561, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8143, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8802, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6602, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1591, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3107, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5941, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1704, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.5022, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2329, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6507, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.5023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.3568, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(8.3174, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.6264, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6333, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4873, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0640, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.9070, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.2986, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.8733, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0859, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7145, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9502, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.6302, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3877, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4641, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3881, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.3622, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0427, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.2243, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1226, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3818, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8652, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.6611, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9200, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1253, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1189, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3796, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4863, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6176, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5724, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1704, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2453, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-14.6602, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2020, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4005, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8862, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.0541, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1889, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2182, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0207, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-13.7196, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7844, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5147, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5954, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.3767, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6874, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0890, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8149, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6734, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.3770, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-12.4997, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3664, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5726, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9142, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.2942, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.4801, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7534, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3727, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.5877, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1737, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.9667, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1578, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5848, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1933, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6163, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9158, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1013, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9380, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3475, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(3.2725, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1836, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0655, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.5485, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0430, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8064, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4936, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5195, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5126, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-10.1811, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.4218, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.3064, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0465, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.3232, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.4978, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0014, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2250, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3202, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4630, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8077, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0200, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2099, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6789, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7275, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0531, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.5200, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0832, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4146, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.5023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.3568, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(6.2761, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.6264, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6333, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5344, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5294, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.6394, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.1776, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.1581, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1263, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7145, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9502, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.2663, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6799, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3108, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3550, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.9597, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0133, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8508, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9396, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3299, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7800, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.8177, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4441, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1567, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1408, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3796, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.9576, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7896, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3702, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1704, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0890, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-15.2358, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9560, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4359, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8862, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2076, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0795, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1119, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1656, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-13.5367, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9403, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4459, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7993, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.4693, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6719, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0567, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6059, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.9829, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-11.8210, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6348, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3259, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6230, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.2942, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.5433, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7534, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.1766, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.5877, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1737, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.5467, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1048, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8573, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2500, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.4816, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0442, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0978, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0230, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2286, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(3.4557, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9766, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7174, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.7393, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0349, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1563, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4313, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4193, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6254, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-10.6050, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.2471, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.9444, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0416, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.3232, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.5530, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5171, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2632, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5298, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8195, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7728, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6173, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1352, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5957, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7275, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1803, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.5007, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7209, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4146, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.5023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.0298, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(7.0133, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.6041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5493, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1511, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9165, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.7155, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.8703, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.1581, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.7225, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2753, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9502, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.8616, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8528, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4256, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7622, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.8205, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8748, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6126, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9396, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2318, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0527, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3106, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1004, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.2053, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1567, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1408, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5246, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0590, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5733, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3663, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8447, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2590, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-15.2839, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0767, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4359, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.5862, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.1689, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7312, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2926, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9002, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-13.6806, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0583, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1059, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1926, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.4693, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6719, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4348, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1118, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0366, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.9426, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8337, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-12.0345, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6348, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9909, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.4945, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.6114, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.2811, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8676, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.6491, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.9399, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0927, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.7134, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0900, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8573, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0064, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.4816, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9884, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4133, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1277, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3376, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(3.4557, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2151, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0921, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.8979, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0349, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1563, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3816, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6064, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5823, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-11.3234, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.2314, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2346, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1531, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.3232, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.7030, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5171, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2630, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3414, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9302, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9205, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7306, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1735, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9323, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4723, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1803, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9087, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6500, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8601, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.5023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.2160, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.4937, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3229, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2282, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1424, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6938, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.7155, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.1606, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.7496, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1995, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1679, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1614, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.3467, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1459, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8629, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5189, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.8205, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7909, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8087, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.7041, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3974, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8740, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2823, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5174, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.0289, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2796, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0184, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4742, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8627, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5733, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3663, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4850, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4839, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-14.4356, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9968, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3388, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.7194, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.3768, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4580, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7852, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9164, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-13.7741, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1267, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2407, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1926, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.4693, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7283, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6037, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8879, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4933, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.2563, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2715, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-12.0345, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0262, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2073, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6111, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.6114, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.4830, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1907, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.8802, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.9399, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1786, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.9212, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0960, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4826, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2015, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.3715, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6970, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8309, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1277, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2193, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(4.4671, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2151, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0921, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.5006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0349, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1563, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3816, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2647, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5823, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-10.9659, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.6534, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-0.1539, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3233, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7707, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.7340, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3659, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2846, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3414, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2236, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0606, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7306, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1174, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4688, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6182, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1803, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0055, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7291, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8601, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.5023, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(0.2160, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.4937, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2646, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-1.3246, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1424, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6468, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.5291, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.0593, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3275, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.2279, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1679, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1614, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.4187, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8858, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8629, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6183, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.1908, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8846, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1098, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.2846, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5602, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8740, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9421, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4469, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.4999, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2834, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9929, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.0541, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8627, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8968, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3663, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8265, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1971, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-14.7255, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9968, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.8514, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.2155, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.9457, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.7852, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.8555, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-14.5730, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1267, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2407, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1926, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.8164, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7283, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6258, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5080, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.9670, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.3295, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5785, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-12.1910, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.2130, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7334, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6751, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.3406, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.2441, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.5141, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.8361, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-9.0754, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.2109, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.6589, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0960, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4826, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1604, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8290, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.3214, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.1184, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.5300, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2193, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.1424, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6324, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6468, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.5006, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0349, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0209, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3816, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1052, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.3834, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-10.5805, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9035, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-0.1539, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2802, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7098, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.7808, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5672, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5585, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6569, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.4207, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.4573, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5878, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.2308, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6105, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.8671, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1803, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.9464, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.6169, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.3442, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.9283, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.0489, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-2.4051, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.1165, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-1.9380, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1720, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6635, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.4352, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-7.0593, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6660, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.2279, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4699, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0594, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-9.3634, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.1201, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5438, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.6183, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.2113, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1113, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.1098, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-6.0292, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.7515, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-3.8396, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9421, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.4469, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-8.8752, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.5308, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-4.0474, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.6959, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " tensor(-5.9923, dtype=torch.float64, grad_fn=<AddBackward0>),\n",
       " ...]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "1a000b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.3259, dtype=torch.float64)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.stack(E_es).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "3374bf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.1468, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(E[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "22348ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.1404, dtype=torch.float64)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e2e350a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_average_energy = running_average(torch.mean(E, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ad01b3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.6816, -2.8029, -2.7848,  ..., -2.8941, -2.8941, -2.8940],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_average_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8146e02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24dbc9441d0>]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cumulative_average_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "55fff58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = E.to(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "0fe151bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0209, dtype=torch.float64)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance in random walkers mean energy\n",
    "torch.mean((torch.mean(E.to(cpu), axis=1) - mean_E) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bfed0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_E_trial = torch.mean(E[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3a665933",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_E_trial = torch.mean((E[0] - mean_E_trial) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d85a2752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3716, dtype=torch.float64)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_E_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "43f8b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = get_dE_dX(sampled_Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5ea524bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([197999, 10, 10])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731a700",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[205], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgradients\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "gradients[:,,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ea881",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = dE_dalpha(reshaped_X, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d6a2b5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0200,  0.9286, -0.3509,  0.0442],\n",
       "        [ 0.0192,  0.9276, -0.3715,  0.0441],\n",
       "        [ 0.0197,  0.9357, -0.3774,  0.0445],\n",
       "        [ 0.0202,  0.9328, -0.4052,  0.0444],\n",
       "        [ 0.0185,  0.9524, -0.3745,  0.0402],\n",
       "        [ 0.0193,  0.9448, -0.3588,  0.0458],\n",
       "        [ 0.0196,  0.9282, -0.3814,  0.0436],\n",
       "        [ 0.0191,  0.9400, -0.3920,  0.0426],\n",
       "        [ 0.0193,  0.9328, -0.3661,  0.0448],\n",
       "        [ 0.0194,  0.9308, -0.3764,  0.0435]], dtype=torch.float64)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b8ce9187",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_X = sampled_Xs.reshape(\n",
    "        sampled_Xs.shape[1], sampled_Xs.shape[0], sampled_Xs.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a547600",
   "metadata": {},
   "source": [
    "Energy value should be −2.901188\n",
    "\n",
    "The actual value is −2.9037243770"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313238f",
   "metadata": {},
   "source": [
    "## Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6373e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "769fd0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_true = -2.9037243770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dda49d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_1 = torch.tensor(0.013, dtype=torch.float64, requires_grad=True) # 1.013\n",
    "alpha_2 = torch.tensor(0.6419, dtype=torch.float64, requires_grad=True) # 0.2119\n",
    "alpha_3 = torch.tensor(0.1406, dtype=torch.float64, requires_grad=True) # 0.1406\n",
    "alpha_4 = torch.tensor(0.103, dtype=torch.float64, requires_grad=True) # 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7f94beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3904007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1031.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean energy is -2.533333871679624\n",
      "Loss is 0.3703905053203762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1051.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean energy is -2.5332306674936587\n",
      "Loss is 0.3704937095063414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 871/5000 [00:00<00:04, 989.91it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     12\u001b[0m     alphas_metropolis \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(alphas)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(n_walkers, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     sampled_Xs \u001b[38;5;241m=\u001b[39m \u001b[43mmetropolis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmet_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_walkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malphas_metropolis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     16\u001b[0m         E \u001b[38;5;241m=\u001b[39m get_local_energies(sampled_Xs)\n",
      "Cell \u001b[1;32mIn[17], line 24\u001b[0m, in \u001b[0;36mmetropolis\u001b[1;34m(N, n_runs, alphas)\u001b[0m\n\u001b[0;32m     22\u001b[0m r1_trial \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(chose \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m, perturbed_r1, r1)\n\u001b[0;32m     23\u001b[0m r2_trial \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(chose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m, perturbed_r2, r2)\n\u001b[1;32m---> 24\u001b[0m psi_val \u001b[38;5;241m=\u001b[39m \u001b[43mpsi_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m psi_trial_val \u001b[38;5;241m=\u001b[39m psi_vec(torch\u001b[38;5;241m.\u001b[39mcat((r1_trial, r2_trial, alphas), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))      \n\u001b[0;32m     26\u001b[0m psi_ratio \u001b[38;5;241m=\u001b[39m psi_trial_val \u001b[38;5;241m/\u001b[39m psi_val\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[1;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[0;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[1;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[1;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[0;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[1;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mpsi\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      4\u001b[0m alpha_1, alpha_2, alpha_3, alpha_4 \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;241m6\u001b[39m:]\n\u001b[0;32m      5\u001b[0m r1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m----> 6\u001b[0m r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m r12 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(x \u001b[38;5;241m-\u001b[39m y)\n\u001b[0;32m      9\u001b[0m term1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (r1 \u001b[38;5;241m+\u001b[39m r2))\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\functional.py:1615\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dim, (\u001b[38;5;28mint\u001b[39m, torch\u001b[38;5;241m.\u001b[39mSymInt)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dim) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m   1614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1615\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1616\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1617\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m2\u001b[39m, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Naive approach - define loss as true energy - found energy\n",
    "\n",
    "epochs = 2000\n",
    "alphas = [alpha_1, alpha_2, alpha_3, alpha_4]\n",
    "losses = []\n",
    "n_walkers = 200\n",
    "met_steps = 5000\n",
    "optimizer = torch.optim.Adam(alphas, lr=0.001)\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    alphas_metropolis = torch.tensor(alphas).unsqueeze(0).repeat(n_walkers, 1)\n",
    "    sampled_Xs = metropolis(met_steps, n_walkers, alphas=alphas_metropolis)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        E = get_local_energies(sampled_Xs)\n",
    "        mean_E = get_mean_energies(E)\n",
    "        loss = torch.abs(E_true - mean_E)\n",
    "\n",
    "        print(f\"Mean energy is {mean_E}\")\n",
    "        print(f\"Loss is {loss}\")\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        reshaped_X = sampled_Xs.reshape(\n",
    "            sampled_Xs.shape[1], sampled_Xs.shape[0], sampled_Xs.shape[2])\n",
    "        gradients = dE_dalpha(reshaped_X, E).to(cpu)\n",
    "\n",
    "        # Now, assume you already have gradients computed externally:\n",
    "        # Example: for step t, these are your gradients (replace with actual values)\n",
    "        gradients = torch.mean(gradients, axis=0)\n",
    "        external_grads = gradients.detach()\n",
    "\n",
    "        # Step 3: Assign gradients manually\n",
    "        for p, g in zip(alphas, external_grads):\n",
    "            p.grad = g  # assign your externally computed gradient\n",
    "\n",
    "    # Step 4: Optimizer step\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    del sampled_Xs\n",
    "    del reshaped_X\n",
    "    del E\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a315675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0752,  3.5492, -0.0362, -0.6221], dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5054dd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.5331, dtype=torch.float64, requires_grad=True), tensor(-0.0537, dtype=torch.float64, requires_grad=True), tensor(0.7332, dtype=torch.float64, requires_grad=True), tensor(-0.0505, dtype=torch.float64, requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4cea79ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_1 = torch.tensor(2.013, dtype=torch.float64, requires_grad=True) # 1.013\n",
    "alpha_2 = torch.tensor(0.6419, dtype=torch.float64, requires_grad=True) # 0.2119\n",
    "alpha_3 = torch.tensor(2.1406, dtype=torch.float64, requires_grad=True) # 0.1406\n",
    "alpha_4 = torch.tensor(3.003, dtype=torch.float64, requires_grad=True) # 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "888e7b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0130, dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "177295f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0080,  0.0429,  0.0155, -0.0305], dtype=torch.float64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6ff3b",
   "metadata": {},
   "source": [
    "## Gradient values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7af58e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dE_dalpha(input):\n",
    "    return jacrev(local_energy)(input)\n",
    "\n",
    "t = dE_dalpha_vec(torch.stack(inputs_arr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4a8a808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dE_dalpha_mean = torch.mean(t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc628ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_vmap = vmap(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "673d69a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_values = psi_vmap(torch.stack(inputs_arr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ad60892",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_energy = sum(energies[0])/(len(energies[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "236e0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "El_Etheta = energies[0] - mean_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c949bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_psi = torch.mean(psi_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0863c591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dE_dalpha_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9541751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "016a8b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9500])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3befeb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_dalph = torch.stack([psi_values[i] * t[i] for i in range(len(t))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7ce5b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9500, 10])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi_dalph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d083d2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dE_dalpha_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36378e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0207, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c80f39eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9500, 10])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "84d9a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = psi_values.unsqueeze(1).repeat(1, 10) * t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "afb6ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (mean_psi * dE_dalpha_mean).unsqueeze(0).repeat(9500, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "01eb27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (energies[0] - mean_energy).unsqueeze(1).repeat(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c54710ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_energy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4fd1249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = (a - b) * (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ec6e08f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0652,  0.4838,  0.4329,  0.0146,  0.1017,  0.0883,  0.0167, -0.0222,\n",
       "        -0.0307,  0.0271], dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(gradients, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d47368b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.6312, dtype=torch.float64, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energies[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7f23a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_fixed = [energies[0][i] / psi_values[i] for i in range(len(inputs_arr[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a25ea1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2546.7772, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.stack(E_fixed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
