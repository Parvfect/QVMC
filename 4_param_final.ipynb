{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31561eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from analytical_expressions import local_energy\n",
    "from torch.autograd.functional import jacobian\n",
    "from torch.func import jacrev\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.func import vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1012fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06526d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(X):\n",
    "    x = X[:3]\n",
    "    y = X[3:6]\n",
    "    alpha_1, alpha_2, alpha_3, alpha_4 = X[6:]\n",
    "    r1 = torch.norm(x)\n",
    "    r2 = torch.norm(y)\n",
    "    r12 = torch.norm(x - y)\n",
    "\n",
    "    term1 = torch.exp(-2 * (r1 + r2))\n",
    "    term2 = 1 + 0.5 * r12 * torch.exp(-alpha_1 * r12)\n",
    "    term3 = 1 + alpha_2 * (r1 + r2) * r12 + alpha_3 * (r1 - r2)**2 - alpha_4 * r12\n",
    "\n",
    "    return term1 * term2 * term3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2407912",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 1\n",
    "r1 = torch.rand(3, requires_grad=False) * 2 * L - L\n",
    "r2 = torch.rand(3, requires_grad=False) * 2 * L - L #random number from -L to L\n",
    "alpha_1 = torch.tensor(1.013, dtype=torch.float64, requires_grad=True) # 1.013\n",
    "alpha_2 = torch.tensor(0.2119, dtype=torch.float64, requires_grad=True)\n",
    "alpha_3 = torch.tensor(0.1406, dtype=torch.float64, requires_grad=True)\n",
    "alpha_4 = torch.tensor(0.003, dtype=torch.float64, requires_grad=True)\n",
    "E = 0\n",
    "E2 = 0\n",
    "Eln_average = 0\n",
    "ln_average = 0\n",
    "rejection_ratio = 0\n",
    "step = 0\n",
    "max_steps = 500\n",
    "N = 10000\n",
    "dlap_dalpha = 0\n",
    "inputs_arr = []\n",
    "n_walkers = 5\n",
    "\n",
    "for walkers in range(n_walkers):\n",
    "    inputs = []\n",
    "    for i in tqdm(range(N)):\n",
    "\n",
    "        chose = np.random.rand()\n",
    "        step = step + 1\n",
    "        if chose < 0.5:\n",
    "            r1_trial = r1 + 0.5 * (torch.rand(3) * 2 * L-L)\n",
    "            r2_trial = r2\n",
    "        else:\n",
    "            r2_trial = r2 + 0.5 * (torch.rand(3) * 2 * L-L)\n",
    "            r1_trial = r1\n",
    "\n",
    "\n",
    "        X = torch.tensor(\n",
    "            [*r1, *r2, alpha_1, alpha_2, alpha_3, alpha_4])\n",
    "        X_trial = torch.tensor(\n",
    "            [*r1_trial, *r2_trial, alpha_1, alpha_2, alpha_3, alpha_4])\n",
    "\n",
    "        psi_val = psi(X)\n",
    "        psi_trial_val = psi(X_trial)\n",
    "\n",
    "\n",
    "        if psi_trial_val >= psi_val:\n",
    "            r1 = r1_trial\n",
    "            r2 = r2_trial\n",
    "            \n",
    "        else:\n",
    "            dummy = np.random.rand()\n",
    "            if dummy < psi_trial_val / psi_val:\n",
    "                r1 = r1_trial\n",
    "                r2 = r2_trial\n",
    "            else:\n",
    "                rejection_ratio += 1./N\n",
    "                    \n",
    "        if step > max_steps:\n",
    "            \n",
    "            X_final = torch.tensor(\n",
    "            [*r1, *r2, alpha_1, alpha_2, alpha_3, alpha_4], requires_grad=True)\n",
    "\n",
    "            #local_E = local_energy(X_final)\n",
    "            #E += local_E / (N - max_steps)\n",
    "            #dlap_dalpha += torch.autograd.grad(local_E, X_final, retain_graph=True)[0][6:] / (N - max_steps)\n",
    "            inputs.append(X_final)\n",
    "\n",
    "    inputs_arr.append(inputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0704f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_vec = vmap(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6f7a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis(N: int, n_runs: int, alphas: torch.tensor):  \n",
    "    \"\"\"\n",
    "    Vectorized metropolis loop\n",
    "    Over N steps, for n_runs. \n",
    "    Alphas passes in must be of same dim as n_runs\n",
    "    \"\"\"  \n",
    "    assert alphas.shape[0] == n_runs        \n",
    "    L = 1\n",
    "    r1 = (torch.rand(n_runs, 3, requires_grad=True) * 2 * L - L)\n",
    "    r2 = (torch.rand(n_runs, 3, requires_grad=True) * 2 * L - L)\n",
    "    max_steps = 1000\n",
    "    sampled_Xs = []\n",
    "    rejection_ratio = 0\n",
    "\n",
    "    for i in tqdm(range(N)):\n",
    "        chose = torch.rand(n_runs).reshape(n_runs, 1)\n",
    "        dummy = torch.rand(n_runs)\n",
    "\n",
    "        perturbed_r1 = r1 + 0.5 * (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "        perturbed_r2 = r2 + 0.5 * (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "\n",
    "        r1_trial = torch.where(chose < 0.5, perturbed_r1, r1)\n",
    "        r2_trial = torch.where(chose >= 0.5, perturbed_r2, r2)\n",
    "        psi_val = psi_vec(torch.cat((r1, r2, alphas), axis=1))\n",
    "        psi_trial_val = psi_vec(torch.cat((r1_trial, r2_trial, alphas), axis=1))      \n",
    "        psi_ratio = psi_trial_val / psi_val\n",
    "\n",
    "        density_comp = psi_trial_val >= psi_val\n",
    "        dummy_comp = dummy < psi_ratio\n",
    "\n",
    "        condition = density_comp + dummy_comp\n",
    "\n",
    "        rejection_ratio += torch.where(condition, 1./N, 0.0)\n",
    "\n",
    "        condition = condition.reshape(condition.shape[0], 1)\n",
    "\n",
    "        # Careful with overwriting\n",
    "        r1 = torch.where(condition, r1_trial, r1)\n",
    "        r2 = torch.where(condition, r2_trial, r2)\n",
    "                \n",
    "        if i > max_steps:\n",
    "            sampled_Xs.append(torch.cat((r1, r2, alphas), axis=1))\n",
    "\n",
    "    return torch.stack(sampled_Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81121059",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_e_vec = vmap(local_energy)\n",
    "local_e_vec_vec = vmap(local_e_vec)\n",
    "\n",
    "def get_local_energies(X):\n",
    "    reshaped_X = X.reshape(\n",
    "        X.shape[1], X.shape[0], X.shape[2])\n",
    "    return local_e_vec_vec(reshaped_X)\n",
    "\n",
    "def get_mean_energies(E):\n",
    "    return torch.mean(E, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9a30834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dE_dalpha(input):\n",
    "    return jacrev(local_energy)(input)\n",
    "\n",
    "dE_dalpha_vec = vmap(dE_dalpha)\n",
    "dE_dalpha_vec_vec = vmap(dE_dalpha_vec)\n",
    "\n",
    "def get_dE_dX(X):\n",
    "    reshaped_X = X.reshape(\n",
    "        X.shape[1], X.shape[0], X.shape[2])\n",
    "    return dE_dalpha_vec_vec(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac777f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_1 = torch.tensor(1.013, dtype=torch.float64, requires_grad=True) # 1.013\n",
    "alpha_2 = torch.tensor(0.2119, dtype=torch.float64, requires_grad=True)\n",
    "alpha_3 = torch.tensor(0.1406, dtype=torch.float64, requires_grad=True)\n",
    "alpha_4 = torch.tensor(0.003, dtype=torch.float64, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b232e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = torch.tensor([alpha_1, alpha_2, alpha_3, alpha_4]).unsqueeze(0).repeat(50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:20<00:00, 624.23it/s]\n"
     ]
    }
   ],
   "source": [
    "sampled_Xs = metropolis(50000, 50, alphas=alphas)\n",
    "# Metropolis is faster on cpu since we do a lot of operations back and forth I suppose? - When the overhead of transferring data to and from the GPU is greater than the benefits of parallel processing. There will be a point at which it'll flip but not currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89e5b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba9afae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = get_local_energies(sampled_Xs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0fca830",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_E = get_mean_energies(E.to(cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5dd6a997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.9382, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(mean_E[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25358b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48999, 50, 10])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sampled_Xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5dad80cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 58.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mget_dE_dX\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_Xs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 10\u001b[0m, in \u001b[0;36mget_dE_dX\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dE_dX\u001b[39m(X):\n\u001b[0;32m      8\u001b[0m     reshaped_X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m      9\u001b[0m         X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdE_dalpha_vec_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[1;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[0;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[1;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[1;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[0;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[1;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[1;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[0;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[1;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[1;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[0;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[1;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m, in \u001b[0;36mdE_dalpha\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdE_dalpha\u001b[39m(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjacrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_energy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\eager_transforms.py:524\u001b[0m, in \u001b[0;36mjacrev.<locals>.wrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m    523\u001b[0m     error_if_complex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacrev\u001b[39m\u001b[38;5;124m\"\u001b[39m, args, is_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 524\u001b[0m     vjp_out \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[0;32m    526\u001b[0m         output, vjp_fn, aux \u001b[38;5;241m=\u001b[39m vjp_out\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[1;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\eager_transforms.py:334\u001b[0m, in \u001b[0;36m_vjp_with_argnums\u001b[1;34m(func, argnums, has_aux, *primals)\u001b[0m\n\u001b[0;32m    332\u001b[0m     diff_primals \u001b[38;5;241m=\u001b[39m _slice_argnums(primals, argnums, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    333\u001b[0m     tree_map_(partial(_create_differentiable, level\u001b[38;5;241m=\u001b[39mlevel), diff_primals)\n\u001b[1;32m--> 334\u001b[0m primals_out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(primals_out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(primals_out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Parv\\Doc\\RA\\Projects\\QVMC\\analytical_expressions.py:143\u001b[0m, in \u001b[0;36mlocal_energy\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlocal_energy\u001b[39m(X):\n\u001b[1;32m--> 143\u001b[0m     ke \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mpsi_laplacian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     r1 \u001b[38;5;241m=\u001b[39m X[:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m    145\u001b[0m     r2 \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m6\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Parv\\Doc\\RA\\Projects\\QVMC\\analytical_expressions.py:133\u001b[0m, in \u001b[0;36mpsi_laplacian\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    131\u001b[0m paa \u001b[38;5;241m=\u001b[39m psi_a_second(X)\n\u001b[0;32m    132\u001b[0m bp \u001b[38;5;241m=\u001b[39m psi_b(X)\n\u001b[1;32m--> 133\u001b[0m pb \u001b[38;5;241m=\u001b[39m \u001b[43mpsi_b_first\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m pbb \u001b[38;5;241m=\u001b[39m psi_b_second(X)\n\u001b[0;32m    135\u001b[0m cp \u001b[38;5;241m=\u001b[39m psi_c(X)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\Doc\\RA\\Projects\\QVMC\\analytical_expressions.py:61\u001b[0m, in \u001b[0;36mpsi_b_first\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     59\u001b[0m r2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(y)\n\u001b[0;32m     60\u001b[0m r12 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(x \u001b[38;5;241m-\u001b[39m y)\n\u001b[1;32m---> 61\u001b[0m r12_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m)\n\u001b[0;32m     63\u001b[0m term1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (r1 \u001b[38;5;241m+\u001b[39m r2))\n\u001b[0;32m     64\u001b[0m term2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m r12 \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39malpha_1 \u001b[38;5;241m*\u001b[39m r12)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\utils\\_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 58.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "gradients = get_dE_dX(sampled_Xs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1a3ffe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_Xs = sampled_Xs.reshape(sampled_Xs.shape[1], sampled_Xs.shape[0], sampled_Xs.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193c54b",
   "metadata": {},
   "source": [
    "Make the rest of the code work with the super-vectorized approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45bf6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dE_dalpha(input):\n",
    "    return jacrev(local_energy)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b788ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import vmap\n",
    "\n",
    "local_e_vec = vmap(local_energy)\n",
    "dE_dalpha_vec = vmap(dE_dalpha)\n",
    "\n",
    "energies = [local_e_vec(torch.stack(inputs_arr[i])) for i in range(len(inputs_arr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "17c60613",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_e_vec_vec = vmap(local_e_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f2634f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_vec = local_e_vec_vec(reshaped_Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d61d7491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.6851, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.mean(E_vec, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd79eb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.8161, dtype=torch.float64, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(energies[0])/(len(energies[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2c46d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.0107, dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([sum(energies[i])/len(energies[i]) for i in range(len(energies))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a547600",
   "metadata": {},
   "source": [
    "Energy value should be −2.901188\n",
    "\n",
    "The actual value is −2.9037243770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b8f2b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dE_dalpha_vec(torch.stack(inputs_arr[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6ff3b",
   "metadata": {},
   "source": [
    "## Gradient values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7af58e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dE_dalpha(input):\n",
    "    return jacrev(local_energy)(input)\n",
    "\n",
    "t = dE_dalpha_vec(torch.stack(inputs_arr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4a8a808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dE_dalpha_mean = torch.mean(t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc628ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_vmap = vmap(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "673d69a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_values = psi_vmap(torch.stack(inputs_arr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ad60892",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_energy = sum(energies[0])/(len(energies[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "236e0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "El_Etheta = energies[0] - mean_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c949bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_psi = torch.mean(psi_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0863c591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dE_dalpha_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9541751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "016a8b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9500])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3befeb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_dalph = torch.stack([psi_values[i] * t[i] for i in range(len(t))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7ce5b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9500, 10])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi_dalph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d083d2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dE_dalpha_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36378e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0207, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c80f39eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9500, 10])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "84d9a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = psi_values.unsqueeze(1).repeat(1, 10) * t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "afb6ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (mean_psi * dE_dalpha_mean).unsqueeze(0).repeat(9500, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "01eb27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (energies[0] - mean_energy).unsqueeze(1).repeat(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c54710ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_energy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4fd1249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = (a - b) * (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ec6e08f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0652,  0.4838,  0.4329,  0.0146,  0.1017,  0.0883,  0.0167, -0.0222,\n",
       "        -0.0307,  0.0271], dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(gradients, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d47368b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.6312, dtype=torch.float64, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energies[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7f23a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_fixed = [energies[0][i] / psi_values[i] for i in range(len(inputs_arr[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a25ea1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2546.7772, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.stack(E_fixed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
