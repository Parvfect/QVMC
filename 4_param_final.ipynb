{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31561eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from analytical_expressions import local_energy\n",
    "from torch.autograd.functional import jacobian\n",
    "from torch.func import jacrev\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.func import vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1012fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06526d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(X):\n",
    "    x = X[:3]\n",
    "    y = X[3:6]\n",
    "    alpha_1, alpha_2, alpha_3, alpha_4 = X[6:]\n",
    "    r1 = torch.norm(x)\n",
    "    r2 = torch.norm(y)\n",
    "    r12 = torch.norm(x - y)\n",
    "\n",
    "    term1 = torch.exp(-2 * (r1 + r2))\n",
    "    term2 = 1 + 0.5 * r12 * torch.exp(-alpha_1 * r12)\n",
    "    term3 = 1 + alpha_2 * (r1 + r2) * r12 + alpha_3 * (r1 - r2)**2 - alpha_4 * r12\n",
    "\n",
    "    return term1 * term2 * term3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0704f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_vec = vmap(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6f7a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis(N: int, n_runs: int, alphas: torch.tensor):  \n",
    "    \"\"\"\n",
    "    Vectorized metropolis loop\n",
    "    Over N steps, for n_runs. \n",
    "    Alphas passes in must be of same dim as n_runs\n",
    "    \"\"\"  \n",
    "    assert alphas.shape[0] == n_runs        \n",
    "    L = 1\n",
    "    r1 = (torch.rand(n_runs, 3, requires_grad=True) * 2 * L - L)\n",
    "    r2 = (torch.rand(n_runs, 3, requires_grad=True) * 2 * L - L)\n",
    "    max_steps = 500\n",
    "    sampled_Xs = []\n",
    "    rejection_ratio = 0\n",
    "\n",
    "    for i in tqdm(range(N)):\n",
    "        chose = torch.rand(n_runs).reshape(n_runs, 1)\n",
    "        dummy = torch.rand(n_runs)\n",
    "\n",
    "        perturbed_r1 = r1 + 0.5 * (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "        perturbed_r2 = r2 + 0.5 * (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "\n",
    "        r1_trial = torch.where(chose < 0.5, perturbed_r1, r1)\n",
    "        r2_trial = torch.where(chose >= 0.5, perturbed_r2, r2)\n",
    "        psi_val = psi_vec(torch.cat((r1, r2, alphas), axis=1))\n",
    "        psi_trial_val = psi_vec(torch.cat((r1_trial, r2_trial, alphas), axis=1))      \n",
    "        psi_ratio = psi_trial_val / psi_val\n",
    "\n",
    "        density_comp = psi_trial_val >= psi_val\n",
    "        dummy_comp = dummy < psi_ratio\n",
    "\n",
    "        condition = density_comp + dummy_comp\n",
    "\n",
    "        rejection_ratio += torch.where(condition, 1./N, 0.0)\n",
    "\n",
    "        condition = condition.reshape(condition.shape[0], 1)\n",
    "\n",
    "        # Careful with overwriting\n",
    "        r1 = torch.where(condition, r1_trial, r1)\n",
    "        r2 = torch.where(condition, r2_trial, r2)\n",
    "                \n",
    "        if i > max_steps:\n",
    "            sampled_Xs.append(torch.cat((r1, r2, alphas), axis=1))\n",
    "\n",
    "    return torch.stack(sampled_Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81121059",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_e_vec = vmap(local_energy)\n",
    "local_e_vec_vec = vmap(local_e_vec)\n",
    "\n",
    "def get_local_energies(X):\n",
    "    reshaped_X = X.reshape(\n",
    "        X.shape[1], X.shape[0], X.shape[2])\n",
    "    return local_e_vec_vec(reshaped_X)\n",
    "\n",
    "def get_mean_energies(E):\n",
    "    return torch.mean(torch.mean(E, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a30834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dE_dalpha(input):\n",
    "    return jacrev(local_energy)(input)\n",
    "\n",
    "dE_dalpha_vec = vmap(dE_dalpha)\n",
    "dE_dalpha_vec_vec = vmap(dE_dalpha_vec)\n",
    "\n",
    "def get_dE_dX(X):\n",
    "    reshaped_X = X.reshape(\n",
    "        X.shape[1], X.shape[0], X.shape[2])\n",
    "    return dE_dalpha_vec_vec(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93c28601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_expressions import get_psi_alpha\n",
    "\n",
    "def get_gradients_from_expression(X_, E_):\n",
    "    psi_alpha = vmap(get_psi_alpha)(X_)\n",
    "\n",
    "    part_1 = psi_alpha - torch.mean(psi_alpha, axis=0)\n",
    "    part_2 = E_ - torch.mean(E_)\n",
    "    return torch.mean(part_1.T * part_2, axis=1)\n",
    "\n",
    "dE_dalpha = vmap(get_gradients_from_expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac777f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_1 = torch.tensor(1.013, dtype=torch.float64, requires_grad=True) # 1.013\n",
    "alpha_2 = torch.tensor(0.2119, dtype=torch.float64, requires_grad=True)\n",
    "alpha_3 = torch.tensor(0.1406, dtype=torch.float64, requires_grad=True)\n",
    "alpha_4 = torch.tensor(0.003, dtype=torch.float64, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5bf74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15d5d9",
   "metadata": {},
   "source": [
    "## Start of simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ef97886",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_1 = torch.tensor(1.013, dtype=torch.float64, requires_grad=True) # 1.013\n",
    "alpha_2 = torch.tensor(0.2119, dtype=torch.float64, requires_grad=True)\n",
    "alpha_3 = torch.tensor(0.1406, dtype=torch.float64, requires_grad=True)\n",
    "alpha_4 = torch.tensor(0.003, dtype=torch.float64, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6b232e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:06<00:00, 823.01it/s]\n"
     ]
    }
   ],
   "source": [
    "n_steps = 200\n",
    "mc_steps = 5000\n",
    "alphas = torch.tensor([alpha_1, alpha_2, alpha_3, alpha_4]).unsqueeze(0).repeat(n_steps, 1)\n",
    "sampled_Xs = metropolis(mc_steps, n_steps, alphas=alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ba9afae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean energy is -2.9016276879729537\n"
     ]
    }
   ],
   "source": [
    "E = get_local_energies(sampled_Xs.to(device))\n",
    "mean_E = get_mean_energies(E.to(cpu))\n",
    "print(f\"Mean energy is {torch.mean(torch.mean(E, axis=1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a48ce08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.7559e-16,  2.7165e-16, -4.2642e-16, -2.9218e-16,  2.8902e-16,\n",
       "        -9.0022e-17,  6.0015e-17, -1.6583e-16, -1.9268e-16, -9.4760e-18,\n",
       "        -1.3977e-16, -3.5535e-18, -2.9297e-16,  2.4578e-16,  7.8967e-17,\n",
       "         1.5793e-17, -5.2118e-17, -1.9386e-16,  9.4760e-18,  2.8744e-16,\n",
       "        -5.6382e-16, -4.7656e-16, -3.0007e-17, -3.4745e-17, -2.1005e-16,\n",
       "        -3.8733e-16, -1.1529e-16,  1.9584e-16,  1.2635e-16, -2.5269e-16,\n",
       "        -3.2060e-16, -3.5693e-16,  2.9455e-16, -2.2032e-16, -3.5535e-17,\n",
       "        -1.2003e-16, -1.7057e-16,  9.1601e-17, -3.3166e-16, -4.9038e-16,\n",
       "        -2.8862e-16, -3.7272e-16, -1.5793e-16, -3.3877e-16, -3.4745e-17,\n",
       "         3.6562e-16, -2.9376e-16, -1.0266e-16,  2.2979e-16, -1.1806e-16,\n",
       "        -2.4361e-16, -2.0531e-17,  4.1142e-16, -2.3374e-16, -2.6888e-16,\n",
       "        -9.4760e-17,  1.5162e-16, -2.5032e-16, -4.2326e-16, -2.2900e-17,\n",
       "        -1.7531e-16,  4.5801e-17, -1.3030e-16, -2.4203e-16, -5.4566e-16,\n",
       "        -1.6820e-16,  2.7875e-16, -1.9110e-16,  1.5991e-16, -2.5901e-16,\n",
       "         2.2821e-16,  1.7689e-16, -1.2319e-16,  1.6109e-16, -4.0431e-16,\n",
       "         6.4753e-17,  5.6066e-17,  1.3108e-16, -1.1055e-17,  1.0976e-16,\n",
       "         7.8967e-19, -2.2150e-16, -6.9096e-17,  6.0804e-17, -1.4806e-16,\n",
       "        -2.8428e-16, -7.3439e-17,  3.0797e-17, -1.5793e-18, -1.5635e-16,\n",
       "         5.3697e-17, -1.6899e-16,  1.2161e-16, -2.7165e-16, -2.9849e-16,\n",
       "        -2.7007e-16, -1.5399e-16, -2.0058e-16, -8.6863e-18, -1.7373e-16,\n",
       "        -3.8852e-16, -5.2276e-16, -1.2082e-16, -1.6978e-16, -1.6267e-16,\n",
       "        -1.2635e-17, -5.9225e-18,  3.9483e-17,  9.1601e-17,  9.1601e-17,\n",
       "        -8.0546e-17,  1.7215e-16,  2.2979e-16,  3.4745e-16,  8.0546e-17,\n",
       "         8.4494e-17, -8.2125e-17, -2.1321e-16, -1.9860e-16, -2.5032e-16,\n",
       "        -2.7678e-16,  7.5018e-17, -4.5564e-16, -6.1594e-17, -4.4221e-17,\n",
       "        -1.1845e-17, -3.5693e-16, -2.2032e-16, -9.3181e-17, -3.7904e-16,\n",
       "        -2.6533e-16,  1.7215e-16,  4.3748e-16,  2.8033e-17,  1.1055e-17,\n",
       "        -3.2534e-16, -1.7925e-16, -3.6009e-16,  2.4006e-16, -3.1113e-16,\n",
       "        -6.3173e-18,  2.5269e-16, -3.8378e-16,  4.1852e-17,  2.9218e-17,\n",
       "        -2.7559e-16, -2.7165e-16, -5.0697e-16,  1.7689e-16, -9.6339e-17,\n",
       "        -6.3015e-16,  2.1953e-16, -2.6414e-16, -2.8507e-16,  1.0266e-17,\n",
       "         7.7387e-17, -3.3482e-16,  1.8320e-16, -3.9839e-16,  1.8320e-16,\n",
       "        -1.7373e-16, -3.5772e-16, -5.1013e-16,  8.0546e-17, -1.8123e-16,\n",
       "         8.0546e-17, -2.2111e-17,  5.8435e-17, -5.1802e-16,  7.8967e-17,\n",
       "         5.5277e-17,  9.4760e-17, -1.8636e-16, -1.2161e-16, -1.0088e-16,\n",
       "         1.3740e-16, -2.8270e-16,  5.5277e-17,  2.0137e-16, -7.9756e-17,\n",
       "        -1.7925e-16,  3.0797e-17, -2.8744e-16,  4.1852e-16, -3.4943e-16,\n",
       "         2.5072e-16, -2.7007e-16, -4.7380e-17,  4.8959e-16,  3.0323e-16,\n",
       "        -2.0294e-16, -2.7796e-16,  3.0323e-16,  1.4056e-16,  1.7768e-16,\n",
       "        -1.1845e-16,  1.2319e-16,  6.0015e-17, -6.0804e-17, -3.0481e-16],\n",
       "       device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(E - torch.mean(E, axis=1).unsqueeze(1).repeat(1, E.shape[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e01b26b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 49499])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ffa2c258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.8646, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(E[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a12e1332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 148999])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4dcb993d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4433e-16, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.mean(E, axis=1) - torch.mean(torch.mean(E, axis=1), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd19134c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4783,  1.3553,  0.7382,  ..., -1.7697, -0.0597,  1.5159],\n",
       "       dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E[0] - torch.mean(E[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5cd4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = torch.sqrt((E - (torch.mean(E, axis=1)).unsqueeze(1).repeat(1, 148999)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d38fb0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2890, dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.mean(variance, axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ea60ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.9562, -2.9060, -2.9096, -2.9558, -2.8629, -2.8733, -2.9745, -2.9979,\n",
       "        -2.9435, -2.9074], dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(E, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79280ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting gradients\n",
    "X_ = sampled_Xs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43f8b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = get_dE_dX(sampled_Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ea524bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8999, 5, 10])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b8ce9187",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_X = sampled_Xs.reshape(\n",
    "        sampled_Xs.shape[1], sampled_Xs.shape[0], sampled_Xs.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a547600",
   "metadata": {},
   "source": [
    "Energy value should be −2.901188\n",
    "\n",
    "The actual value is −2.9037243770"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313238f",
   "metadata": {},
   "source": [
    "## Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6373e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "769fd0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_true = -2.9037243770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda49d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_1 = torch.tensor(0.013, dtype=torch.float64, requires_grad=True) # 1.013\n",
    "alpha_2 = torch.tensor(0.6419, dtype=torch.float64, requires_grad=True) # 0.2119\n",
    "alpha_3 = torch.tensor(0.1406, dtype=torch.float64, requires_grad=True) # 0.1406\n",
    "alpha_4 = torch.tensor(0.103, dtype=torch.float64, requires_grad=True) # 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b7f94beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d3904007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:06<00:00, 813.79it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m sampled_Xs \u001b[38;5;241m=\u001b[39m metropolis(met_steps, n_walkers, alphas\u001b[38;5;241m=\u001b[39malphas_metropolis)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 16\u001b[0m     E \u001b[38;5;241m=\u001b[39m \u001b[43mget_local_energies\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_Xs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     mean_E \u001b[38;5;241m=\u001b[39m get_mean_energies(E)\n\u001b[0;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(E_true \u001b[38;5;241m-\u001b[39m mean_E)\n",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m, in \u001b[0;36mget_local_energies\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_local_energies\u001b[39m(X):\n\u001b[0;32m      5\u001b[0m     reshaped_X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m      6\u001b[0m         X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlocal_e_vec_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreshaped_X\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[1;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[0;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[1;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[1;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[0;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[1;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[1;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[0;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[1;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[1;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[0;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[1;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\Doc\\RA\\Projects\\QVMC\\analytical_expressions.py:143\u001b[0m, in \u001b[0;36mlocal_energy\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlocal_energy\u001b[39m(X):\n\u001b[1;32m--> 143\u001b[0m     ke \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mpsi_laplacian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     r1 \u001b[38;5;241m=\u001b[39m X[:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m    145\u001b[0m     r2 \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m6\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Parv\\Doc\\RA\\Projects\\QVMC\\analytical_expressions.py:130\u001b[0m, in \u001b[0;36mpsi_laplacian\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Full Laplacian - hessian verified \"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m ap \u001b[38;5;241m=\u001b[39m psi_a(X)\n\u001b[1;32m--> 130\u001b[0m pa \u001b[38;5;241m=\u001b[39m \u001b[43mpsi_a_first\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m paa \u001b[38;5;241m=\u001b[39m psi_a_second(X)\n\u001b[0;32m    132\u001b[0m bp \u001b[38;5;241m=\u001b[39m psi_b(X)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\Doc\\RA\\Projects\\QVMC\\analytical_expressions.py:26\u001b[0m, in \u001b[0;36mpsi_a_first\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     22\u001b[0m r2_ \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m y[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m y[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     24\u001b[0m term1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (r1 \u001b[38;5;241m+\u001b[39m r2))\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mterm1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m term1 \u001b[38;5;241m*\u001b[39m (X[i] \u001b[38;5;241m/\u001b[39m r2) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m6\u001b[39m)])\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "# Naive approach - define loss as true energy - found energy\n",
    "\n",
    "epochs = 2000\n",
    "alphas = [alpha_1, alpha_2, alpha_3, alpha_4]\n",
    "losses = []\n",
    "n_walkers = 200\n",
    "met_steps = 5000\n",
    "optimizer = torch.optim.Adam(alphas, lr=0.001)\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    alphas_metropolis = torch.tensor(alphas).unsqueeze(0).repeat(n_walkers, 1)\n",
    "    sampled_Xs = metropolis(met_steps, n_walkers, alphas=alphas_metropolis)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        E = get_local_energies(sampled_Xs.to(device))\n",
    "        mean_E = get_mean_energies(E)\n",
    "        loss = torch.abs(E_true - mean_E)\n",
    "\n",
    "        print(f\"Mean energy is {mean_E}\")\n",
    "        print(f\"Loss is {loss}\")\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        reshaped_X = sampled_Xs.reshape(\n",
    "            sampled_Xs.shape[1], sampled_Xs.shape[0], sampled_Xs.shape[2])\n",
    "        gradients = dE_dalpha(reshaped_X.to(device), E).to(cpu)\n",
    "\n",
    "        # Now, assume you already have gradients computed externally:\n",
    "        # Example: for step t, these are your gradients (replace with actual values)\n",
    "        gradients = torch.mean(gradients, axis=0)\n",
    "        external_grads = gradients.detach()\n",
    "\n",
    "        # Step 3: Assign gradients manually\n",
    "        for p, g in zip(alphas, external_grads):\n",
    "            p.grad = g  # assign your externally computed gradient\n",
    "\n",
    "    # Step 4: Optimizer step\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    del sampled_Xs\n",
    "    del reshaped_X\n",
    "    del E\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a315675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0752,  3.5492, -0.0362, -0.6221], dtype=torch.float64,\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5054dd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.5331, dtype=torch.float64, requires_grad=True), tensor(-0.0537, dtype=torch.float64, requires_grad=True), tensor(0.7332, dtype=torch.float64, requires_grad=True), tensor(-0.0505, dtype=torch.float64, requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4cea79ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_1 = torch.tensor(2.013, dtype=torch.float64, requires_grad=True) # 1.013\n",
    "alpha_2 = torch.tensor(0.6419, dtype=torch.float64, requires_grad=True) # 0.2119\n",
    "alpha_3 = torch.tensor(2.1406, dtype=torch.float64, requires_grad=True) # 0.1406\n",
    "alpha_4 = torch.tensor(3.003, dtype=torch.float64, requires_grad=True) # 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "888e7b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0130, dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "177295f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0080,  0.0429,  0.0155, -0.0305], dtype=torch.float64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6ff3b",
   "metadata": {},
   "source": [
    "## Gradient values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7af58e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dE_dalpha(input):\n",
    "    return jacrev(local_energy)(input)\n",
    "\n",
    "t = dE_dalpha_vec(torch.stack(inputs_arr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4a8a808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dE_dalpha_mean = torch.mean(t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc628ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_vmap = vmap(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "673d69a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_values = psi_vmap(torch.stack(inputs_arr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ad60892",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_energy = sum(energies[0])/(len(energies[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "236e0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "El_Etheta = energies[0] - mean_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c949bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_psi = torch.mean(psi_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0863c591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dE_dalpha_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9541751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "016a8b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9500])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3befeb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_dalph = torch.stack([psi_values[i] * t[i] for i in range(len(t))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7ce5b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9500, 10])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi_dalph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d083d2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dE_dalpha_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36378e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0207, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c80f39eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9500, 10])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "84d9a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = psi_values.unsqueeze(1).repeat(1, 10) * t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "afb6ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (mean_psi * dE_dalpha_mean).unsqueeze(0).repeat(9500, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "01eb27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (energies[0] - mean_energy).unsqueeze(1).repeat(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c54710ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_energy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4fd1249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = (a - b) * (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ec6e08f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0652,  0.4838,  0.4329,  0.0146,  0.1017,  0.0883,  0.0167, -0.0222,\n",
       "        -0.0307,  0.0271], dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(gradients, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d47368b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.6312, dtype=torch.float64, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energies[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7f23a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_fixed = [energies[0][i] / psi_values[i] for i in range(len(inputs_arr[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a25ea1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2546.7772, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.stack(E_fixed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
