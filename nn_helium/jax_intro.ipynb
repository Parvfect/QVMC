{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a432f0",
   "metadata": {},
   "source": [
    "## JAX VMC\n",
    "Code taken from - https://teddykoker.com/2024/11/neural-vmc-jax/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54c27d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002fae99",
   "metadata": {},
   "source": [
    "### Local energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ce0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_energy(wavefunction, atoms, charges, pos):\n",
    "    return kinetic_energy(wavefunction, pos) + potential_energy(atoms, charges, pos)\n",
    "\n",
    "def kinetic_energy(wavefunction, pos):\n",
    "    \"\"\"Kinetic energy term of Hamiltonian\"\"\"\n",
    "    laplacian = jnp.trace(jax.hessian(wavefunction)(pos))\n",
    "    return -0.5 * laplacian / wavefunction(pos)\n",
    "\n",
    "def potential_energy(pos):\n",
    "\n",
    "    r1 = jnp.linalg.norm(pos[:, :, :3], axis=-1)\n",
    "    r2 = jnp.linalg.norm(pos[:, :, 3:], axis=-1)\n",
    "    r12 = jnp.linalg.norm(pos[:, :, :3] - pos[:, :, 3:], axis=-1)\n",
    "    eps = 1e-8\n",
    "    return -2 / (r1 + eps) - 2 / (r2 + eps) + 1 / (r12 + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ecedc2",
   "metadata": {},
   "source": [
    "### Metropolis sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf084988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "from functools import partial\n",
    "from collections.abc import Callable\n",
    "\n",
    "@eqx.filter_jit\n",
    "@partial(jax.vmap, in_axes=(None, 0, None, None, 0))\n",
    "def metropolis(\n",
    "    wavefunction: Callable,\n",
    "    pos: jax.Array,\n",
    "    step_size: float,\n",
    "    mcmc_steps: int,\n",
    "    key: jax.Array,\n",
    "):\n",
    "    \"\"\"MCMC step\n",
    "\n",
    "    Args:\n",
    "        wavefunction: neural wavefunction\n",
    "        pos: [3N] current electron positions flattened\n",
    "        step_size: std of proposal for metropolis sampling\n",
    "        mcmc_steps: number of steps to perform\n",
    "        key: random key\n",
    "    \"\"\"\n",
    "\n",
    "    def step(_, carry):\n",
    "        pos, prob, num_accepts, key = carry\n",
    "        key, subkey = jax.random.split(key)\n",
    "        pos_proposal = pos + step_size * jax.random.normal(subkey, shape=pos.shape)\n",
    "        prob_proposal = wavefunction(pos_proposal) ** 2\n",
    "\n",
    "        key, subkey = jax.random.split(key)\n",
    "        accept = jax.random.uniform(subkey) < prob_proposal / prob\n",
    "        prob = jnp.where(accept, prob_proposal, prob)\n",
    "        pos = jnp.where(accept, pos_proposal, pos)\n",
    "        num_accepts = num_accepts + jnp.sum(accept)\n",
    "\n",
    "        return pos, prob, num_accepts, key\n",
    "\n",
    "    prob = wavefunction(pos) ** 2\n",
    "    carry = (pos, prob, 0, key)\n",
    "    pos, prob, num_accepts, key = jax.lax.fori_loop(0, mcmc_steps, step, carry)\n",
    "    return pos, num_accepts / mcmc_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "015f0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavefunction_h(pos):\n",
    "    return jnp.exp(-jnp.linalg.norm(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900081f",
   "metadata": {},
   "source": [
    "### Neural network, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2af69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loss(atoms, charges):\n",
    "    # Based on implementation in https://github.com/google-deepmind/ferminet/\n",
    "\n",
    "    @eqx.filter_custom_jvp\n",
    "    def total_energy(wavefunction, pos):\n",
    "        \"\"\"Define L()\"\"\"\n",
    "        batch_local_energy = jax.vmap(local_energy, (None, None, None, 0))\n",
    "        e_l = batch_local_energy(wavefunction, atoms, charges, pos)\n",
    "        loss = jnp.mean(e_l)\n",
    "        return loss, e_l\n",
    "\n",
    "    @total_energy.def_jvp\n",
    "    def total_energy_jvp(primals, tangents):\n",
    "        \"\"\"Define the gradient of L()\"\"\"\n",
    "        wavefunction, pos = primals\n",
    "        log_wavefunction = lambda psi, pos: jnp.log(psi(pos))\n",
    "        batch_wavefunction = jax.vmap(log_wavefunction, (None, 0))\n",
    "        psi_primal, psi_tangent = eqx.filter_jvp(batch_wavefunction, primals, tangents)\n",
    "        loss, local_energy = total_energy(wavefunction, pos)\n",
    "        primals_out = loss, local_energy\n",
    "        batch_size = jnp.shape(local_energy)[0]\n",
    "        tangents_out = (jnp.dot(psi_tangent, local_energy - loss) / batch_size, local_energy)\n",
    "        return primals_out, tangents_out\n",
    "\n",
    "    return total_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c770a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(eqx.Module):\n",
    "    \"\"\"Linear layer\"\"\"\n",
    "\n",
    "    weights: jax.Array\n",
    "    bias: jax.Array\n",
    "\n",
    "    def __init__(self, in_size, out_size, key):\n",
    "        lim = math.sqrt(1 / (in_size + out_size))\n",
    "        self.weights = jax.random.uniform(key, (in_size, out_size), minval=-lim, maxval=lim)\n",
    "        self.bias = jnp.zeros(out_size)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return jnp.dot(x, self.weights) + self.bias\n",
    "\n",
    "\n",
    "class PsiMLP(eqx.Module):\n",
    "    \"\"\"Simple MLP-based model using Slater determinant\"\"\"\n",
    "\n",
    "    spins: tuple[int, int]\n",
    "    linears: list[Linear]\n",
    "    orbitals: Linear\n",
    "    sigma: jax.Array \n",
    "    pi: jax.Array\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_sizes: list[int],\n",
    "        spins: tuple[int, int],\n",
    "        determinants: int,\n",
    "        key: jax.Array,\n",
    "    ):\n",
    "        num_atoms = 1  # assume one atom\n",
    "        sizes = [5] + hidden_sizes  # 5 input features\n",
    "        key, *keys = jax.random.split(key, len(sizes))\n",
    "        self.linears = []\n",
    "        for i in range(len(sizes) - 1):\n",
    "            self.linears.append(Linear(sizes[i], sizes[i + 1], keys[i]))\n",
    "        self.orbitals = Linear(sizes[-1], sum(spins) * determinants, key)\n",
    "        self.sigma = jnp.ones((num_atoms, sum(spins) * determinants))\n",
    "        self.pi = jnp.ones((num_atoms, sum(spins) * determinants))\n",
    "        self.spins = spins\n",
    "\n",
    "    def __call__(self, pos):\n",
    "        # atom electron displacement [electron, atom, 3]\n",
    "        ae = pos.reshape(-1, 1, 3)\n",
    "        # atom electron distance [electron, atom, 1]\n",
    "        r_ae = jnp.linalg.norm(ae, axis=2, keepdims=True)\n",
    "        # feature for spins; 1 for up, -1 for down [atom, 1]\n",
    "        spins = jnp.concatenate([jnp.ones(self.spins[0]), jnp.ones(self.spins[1]) * -1])\n",
    "\n",
    "        # combine into features\n",
    "        h = jnp.concatenate([ae, r_ae], axis=2)\n",
    "        h = h.reshape([h.shape[0], -1])\n",
    "        h = jnp.concatenate([h, spins[:, None]], axis=1)\n",
    "\n",
    "        # multi-layer perceptron with tanh activations\n",
    "        for linear in self.linears:\n",
    "            h = jnp.tanh(linear(h))\n",
    "\n",
    "        phi = self.orbitals(h) * jnp.sum(self.pi * jnp.exp(-self.sigma * r_ae), axis=1)\n",
    "\n",
    "        # [electron, electron * determinants] -> [determinants, electron, electron]\n",
    "        phi = phi.reshape(phi.shape[0], -1, phi.shape[0]).transpose(1, 0, 2)\n",
    "        det = jnp.linalg.det(phi)\n",
    "        return jnp.sum(det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa55ad2f",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16eb3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from tqdm import tqdm\n",
    "\n",
    "def vmc(\n",
    "    wavefunction: Callable,\n",
    "    atoms: jax.Array,\n",
    "    charges: jax.Array,\n",
    "    spins: tuple[int, int],\n",
    "    *,\n",
    "    batch_size: int = 4096,\n",
    "    mcmc_steps: int = 50,\n",
    "    warmup_steps: int = 200,\n",
    "    init_width: float = 0.4,\n",
    "    step_size: float = 0.2,\n",
    "    learning_rate: float = 3e-3,\n",
    "    iterations: int = 2_000,\n",
    "    key: jax.Array,\n",
    "):\n",
    "    \"\"\"Perform variational Monte Carlo\n",
    "\n",
    "    Args:\n",
    "        wavefunction: neural wavefunction\n",
    "        atoms: [M, 3] atomic positions\n",
    "        charges: [M] atomic charges\n",
    "        spins: number spin-up, spin-down electrons\n",
    "        batch_size: number of electron configurations to sample\n",
    "        mcmc_steps: number of mcmc steps to perform between neural network\n",
    "            updates (lessens autocorrelation)\n",
    "        warmup_steps: number of mcmc steps to perform before starting training\n",
    "        step_size: std of proposal for metropolis sampling\n",
    "        learning_rate: learning rate\n",
    "        iterations: number of neural network updates\n",
    "        key: random key\n",
    "    \"\"\"\n",
    "    total_energy = make_loss(atoms, charges)\n",
    "\n",
    "    # initialize electron positions and perform warmup mcmc steps\n",
    "    key, subkey = jax.random.split(key)\n",
    "    pos = init_width * jax.random.normal(subkey, shape=(batch_size, sum(spins) * 3))\n",
    "    key, *subkeys = jax.random.split(key, batch_size + 1)\n",
    "    pos, _ = metropolis(wavefunction, pos, step_size, warmup_steps, jnp.array(subkeys))\n",
    "\n",
    "    # Adam optimizer with gradient clipping\n",
    "    optimizer = optax.chain(optax.clip_by_global_norm(1.0), optax.adam(learning_rate))\n",
    "    opt_state = optimizer.init(eqx.filter(wavefunction, eqx.is_array))\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def train_step(wavefunction, pos, key, opt_state):\n",
    "        key, *subkeys = jax.random.split(key, batch_size + 1)\n",
    "        pos, accept = metropolis(wavefunction, pos, step_size, mcmc_steps, jnp.array(subkeys))\n",
    "        (loss, _), grads = eqx.filter_value_and_grad(total_energy, has_aux=True)(wavefunction, pos)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state, wavefunction)\n",
    "        wavefunction = eqx.apply_updates(wavefunction, updates)\n",
    "        return wavefunction, pos, key, opt_state, loss, accept\n",
    "\n",
    "    losses, pmoves = [], []\n",
    "    pbar = tqdm(range(iterations))\n",
    "    for _ in pbar:\n",
    "        wavefunction, pos, key, opt_state, loss, pmove = train_step(wavefunction, pos, key, opt_state)\n",
    "        pmove = pmove.mean()\n",
    "        losses.append(loss)\n",
    "        pmoves.append(pmove)\n",
    "        pbar.set_description(f\"Energy: {loss:.4f}, P(move): {pmove:.2f}\")\n",
    "\n",
    "    return losses, pmoves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304e6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lithium at origin\n",
    "atoms = jnp.zeros((1, 2))\n",
    "charges = jnp.array([3.0])\n",
    "spins = (2, 1) # 2 spin-up, 1 spin-down electrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4199f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 0.4 * jax.random.normal(key, shape=(4096, sum(spins) * 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c520f417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ad109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: -6.3426, P(move): 0.61:   2%|▏         | 46/2000 [00:38<27:15,  1.20it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m key, subkey \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(key)\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m PsiMLP(hidden_sizes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m], determinants\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, spins\u001b[38;5;241m=\u001b[39mspins, key\u001b[38;5;241m=\u001b[39mkey)\n\u001b[1;32m----> 4\u001b[0m losses, _ \u001b[38;5;241m=\u001b[39m \u001b[43mvmc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matoms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 59\u001b[0m, in \u001b[0;36mvmc\u001b[1;34m(wavefunction, atoms, charges, spins, batch_size, mcmc_steps, warmup_steps, init_width, step_size, learning_rate, iterations, key)\u001b[0m\n\u001b[0;32m     57\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(iterations))\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m---> 59\u001b[0m     wavefunction, pos, key, opt_state, loss, pmove \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwavefunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     pmove \u001b[38;5;241m=\u001b[39m pmove\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     61\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\jax_cuda\\lib\\site-packages\\equinox\\_jit.py:271\u001b[0m, in \u001b[0;36m_call\u001b[1;34m(jit_wrapper, is_lower, args, kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;66;03m# We need to include the explicit `isinstance(marker, jax.Array)` check due\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# to https://github.com/patrick-kidger/equinox/issues/988\u001b[39;00m\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(marker, jax\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mTracer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    269\u001b[0m         marker, jax\u001b[38;5;241m.\u001b[39mArray\n\u001b[0;32m    270\u001b[0m     ):\n\u001b[1;32m--> 271\u001b[0m         \u001b[43mmarker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_until_ready\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JaxRuntimeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# Catch Equinox's runtime errors, and re-raise them with actually useful\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;66;03m# information. (By default XlaRuntimeError produces a lot of terrifying\u001b[39;00m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# but useless information.)\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_error_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_EquinoxRuntimeError: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "key = jax.random.key(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "model = PsiMLP(hidden_sizes=[64, 64, 64], determinants=4, spins=spins, key=key)\n",
    "losses, _ = vmc(wavefunction_h, atoms, charges, spins, key=subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13045eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
