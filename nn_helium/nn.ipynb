{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9273957a",
   "metadata": {},
   "source": [
    "## Starter notebook for MLP ansatz for Helium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64533c",
   "metadata": {},
   "source": [
    "1. Energy - using Hessian,\n",
    "2. Gradients - using known formula (update manually),\n",
    "3. Optimization - ADAM.\n",
    "\n",
    "First, non-symmetric, without Jastrow factor, to slowly add complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d0d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch import vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c2d90",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dad35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, n_hidden_layers, hidden_dim, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.Tanh())\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(n_hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "\n",
    "        # Output layer (no activation here by default)\n",
    "        layers.append(nn.Linear(hidden_dim, output_size))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25835cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = 6\n",
    "n_hidden_layers = 2\n",
    "hidden_dim = 32\n",
    "output_size = 1\n",
    "\n",
    "network = MLP(\n",
    "    input_dim=input_dim,\n",
    "    n_hidden_layers=n_hidden_layers,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_size=output_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c227514a",
   "metadata": {},
   "source": [
    "### Metropolis sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea11922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis(N: int, n_runs: int, model: nn.Module):  \n",
    "    \"\"\"\n",
    "    Vectorized metropolis loop\n",
    "    Over N steps, for n_runs. \n",
    "    Alphas passes in must be of same dim as n_runs\n",
    "    \"\"\"       \n",
    "    L = 1\n",
    "    r1 = (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "    r2 = (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "    max_steps = 500\n",
    "    sampled_Xs = []\n",
    "    rejection_ratio = 0\n",
    "\n",
    "    for i in tqdm(range(N)):\n",
    "        chose = torch.rand(n_runs).reshape(n_runs, 1)\n",
    "        dummy = torch.rand(n_runs)\n",
    "\n",
    "        perturbed_r1 = r1 + 0.5 * (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "        perturbed_r2 = r2 + 0.5 * (torch.rand(n_runs, 3) * 2 * L - L)\n",
    "\n",
    "        r1_trial = torch.where(chose < 0.5, perturbed_r1, r1)\n",
    "        r2_trial = torch.where(chose >= 0.5, perturbed_r2, r2)\n",
    "        psi_val = model(torch.cat((r1, r2), axis=1)).squeeze()\n",
    "        psi_trial_val = model(torch.cat((r1_trial, r2_trial), axis=1)).squeeze()\n",
    "\n",
    "        \n",
    "        psi_ratio = (psi_trial_val / psi_val) ** 2\n",
    "\n",
    "        dummy_comp = psi_ratio > dummy\n",
    "\n",
    "        condition = dummy_comp\n",
    "\n",
    "        rejection_ratio += torch.where(condition, 1./N, 0.0)\n",
    "\n",
    "        condition = condition.reshape(condition.shape[0], 1)\n",
    "\n",
    "        r1 = torch.where(condition, r1_trial, r1)\n",
    "        r2 = torch.where(condition, r2_trial, r2)\n",
    "                \n",
    "        if i > max_steps:\n",
    "            sampled_Xs.append(torch.cat((r1, r2), axis=1))\n",
    "\n",
    "    return torch.stack(sampled_Xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84de57",
   "metadata": {},
   "source": [
    "### Local energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "675510e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the simplest one - all the positions\n",
    "\n",
    "def local_energy(positions):\n",
    "    # positions: [batch_size, 6] with [r1x, r1y, r1z, r2x, r2y, r2z]\n",
    "    positions.requires_grad_(True)\n",
    "    psi = network(positions).squeeze()\n",
    "\n",
    "    # Gradient of log_psi w.r.t positions\n",
    "    grads = torch.autograd.grad(psi.sum(), positions, create_graph=True)[0]\n",
    "\n",
    "    # Laplacian: second derivative (sum of second partials)\n",
    "    laplacian = 0\n",
    "    for i in range(positions.shape[1]):\n",
    "        grad_i = grads[:, i]\n",
    "        grad2 = torch.autograd.grad(grad_i.sum(), positions, create_graph=True)[0][:, i]\n",
    "        laplacian += grad2\n",
    "\n",
    "    # Kinetic energy\n",
    "    kinetic = -0.5 * (laplacian) / psi \n",
    "\n",
    "    # Reshape positions\n",
    "    r1 = positions[:, 0:3]\n",
    "    r2 = positions[:, 3:6]\n",
    "    r1_norm = torch.norm(r1, dim=1)\n",
    "    r2_norm = torch.norm(r2, dim=1)\n",
    "    r12 = torch.norm(r1 - r2, dim=1)\n",
    "\n",
    "    potential = -2 / r1_norm - 2 / r2_norm + 1 / r12\n",
    "\n",
    "    E_local = kinetic + potential\n",
    "    return E_local\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa37532",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed2efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch import make_functional, vmap, grad\n",
    "\n",
    "def get_gradients_walkers(x, E, network):\n",
    "    \"\"\"\n",
    "    x: [n_walkers, batch_size, 6]\n",
    "    E: [n_walkers, batch_size]\n",
    "    Returns:\n",
    "        gradients: [n_walkers, n_parameters]\n",
    "    \"\"\"\n",
    "    n_walkers, batch_size, _ = x.shape\n",
    "\n",
    "    # Convert model to functional\n",
    "    fmodel, params = make_functional(network)\n",
    "\n",
    "    # Define single-sample log Ψ\n",
    "    def log_psi_single(params, x):\n",
    "        return fmodel(params, x)\n",
    "\n",
    "    # Compute ∇θ log Ψ per sample\n",
    "    grads_per_sample = vmap(grad(log_psi_single), in_dims=(None, 0))(params, x)\n",
    "\n",
    "    # Flatten parameter structure: list of tensors → single [n_walkers * batch_size, n_params]\n",
    "    grads_flat = torch.cat([g.reshape(x_flat.shape[0], -1) for g in grads_per_sample], dim=1)\n",
    "\n",
    "    # Reshape grads and E to [n_walkers, batch_size, n_params]\n",
    "    grads_flat = grads_flat.view(n_walkers, batch_size, -1)\n",
    "    E = E.view(n_walkers, batch_size)\n",
    "\n",
    "    # Mean gradients and energies per walker\n",
    "    mean_grad = grads_flat.mean(dim=1)      # [n_walkers, n_params]\n",
    "    mean_E = E.mean(dim=1, keepdim=True)    # [n_walkers, 1]\n",
    "\n",
    "    # Compute centered quantities\n",
    "    centered_E = E - mean_E                 # [n_walkers, batch_size]\n",
    "    centered_grads = grads_flat - mean_grad.unsqueeze(1)  # broadcast\n",
    "\n",
    "    # Final VMC gradient: [n_walkers, n_params]\n",
    "    vmc_grad = torch.mean(centered_E.unsqueeze(2) * centered_grads, dim=1)\n",
    "\n",
    "    return vmc_grad  # [n_walkers, n_parameters]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "149b4767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\deprecated.py:100: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.make_functional is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.functional_call instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('make_functional', 'torch.func.functional_call')\n"
     ]
    }
   ],
   "source": [
    "fmodel, params = make_functional(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cb34dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf(x):\n",
    "    return fmodel(params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c84e3c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\deprecated.py:65: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "c:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "t = vmap(grad(inf), in_dims=(None, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7b378190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(params, x):\n",
    "    return fmodel(params, x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1d29c4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4499])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode(params, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f98e4b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -8.1484,   4.6863,  -1.5537,  -0.3887,   1.7971,   2.5163],\n",
       "        [ -8.1484,   4.6863,  -1.5537,  -0.1113,   1.4717,   2.9053],\n",
       "        [ -8.1484,   4.6863,  -1.5537,   0.2571,   1.7718,   3.0985],\n",
       "        ...,\n",
       "        [-17.7867, -13.3441, -11.6457, -10.5974,   9.3614,   4.9027],\n",
       "        [-17.7867, -13.3441, -11.6457, -10.4786,   9.2392,   4.6427],\n",
       "        [-17.7867, -13.3441, -11.6457, -10.8582,   9.0171,   4.4217]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769655f",
   "metadata": {},
   "source": [
    "### Calling and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c1c2d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\deprecated.py:100: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.make_functional is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.functional_call instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('make_functional', 'torch.func.functional_call')\n",
      "c:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\deprecated.py:65: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.grad is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.grad instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('grad')\n",
      "c:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "from functorch import make_functional\n",
    "\n",
    "fmodel, params = make_functional(network)\n",
    "\n",
    "def f(params, x):\n",
    "    return fmodel(params, x.unsqueeze(0)).squeeze()\n",
    "\n",
    "grad_f = grad(f)\n",
    "grads = vmap(grad_f, in_dims=(None, 0))(params, x)  # list of [batch_size, ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bcfe4ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parv\\AppData\\Local\\Temp\\ipykernel_13768\\1121398151.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  print(p[0].grad)\n"
     ]
    }
   ],
   "source": [
    "for p in params:\n",
    "    print(p[0].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "92d459b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_grads = torch.cat([g.view(-1) for g in grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c7cbf377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5907187])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7ae096b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4499, 32, 6])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1c6411f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4499, 32])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "40f891e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "af3daded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0283, -0.0063,  0.0159, -0.0124, -0.0445,  0.0456],\n",
       "        [-0.0109, -0.0166,  0.0169,  0.0162, -0.0520,  0.0775],\n",
       "        [-0.0458, -0.0235,  0.0074,  0.0154, -0.0717,  0.1039],\n",
       "        [-0.0499, -0.0336, -0.0085,  0.0265, -0.0578,  0.0791],\n",
       "        [ 0.0020, -0.0320,  0.0385,  0.0206, -0.0658,  0.0646],\n",
       "        [-0.0322, -0.0060,  0.0163,  0.0084, -0.0385,  0.0681],\n",
       "        [-0.0312, -0.0502,  0.0234, -0.0011, -0.0780,  0.0813],\n",
       "        [-0.0636, -0.0264, -0.0113,  0.0265, -0.0612,  0.0998],\n",
       "        [-0.0243, -0.0439,  0.0143,  0.0185, -0.0659,  0.0828],\n",
       "        [-0.0272, -0.0013, -0.0066,  0.0192, -0.0511,  0.0587]],\n",
       "       grad_fn=<SqueezeBackward2>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "65df7283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.0234, -1.2570, -2.6814,  0.7713,  1.9691],\n",
       "        [-4.0000, -2.2121, -0.6792, -0.9052, -1.9934],\n",
       "        [ 0.8249,  1.9552, -2.2715, -0.8959, -0.3449],\n",
       "        [-2.1716, -0.6094,  1.7183,  0.0491, -2.6119],\n",
       "        [ 2.0293,  3.6102,  1.3915,  3.0094, -0.2820],\n",
       "        [-2.3896, -3.3258,  0.4831,  0.4983, -0.9949],\n",
       "        [ 0.5123, -2.2230, -2.4487,  3.0820,  1.6691],\n",
       "        [ 0.9562, -1.6421,  2.3684, -1.9525, -2.6460],\n",
       "        [ 4.3113,  0.1937, -4.5661, -0.8182,  3.2101],\n",
       "        [ 0.0471,  4.0138, -0.4707,  0.2721,  0.0478]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17dd55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "n_walkers = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf2a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1981.40it/s]\n"
     ]
    }
   ],
   "source": [
    "sampled_Xs = metropolis(N, n_walkers, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4cb626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_E = torch.stack([local_energy(sampled_Xs[:, i]) for i in range(n_walkers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5b7ce06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_Xs = sampled_Xs.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9eceb9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 4499, 6])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "987707b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 4499])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1af6c83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_functorch\\deprecated.py:100: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.make_functional is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.functional_call instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('make_functional', 'torch.func.functional_call')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mget_gradients_walkers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreshaped_Xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_E\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[115], line 20\u001b[0m, in \u001b[0;36mget_gradients_walkers\u001b[1;34m(x, E, network)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fmodel(params, xi\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Get per-sample grads: output is List[tensor], each [n_walkers*batch_size, ...]\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m x_flat \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m              \u001b[38;5;66;03m# [n_walkers * batch_size, 6]\u001b[39;00m\n\u001b[0;32m     21\u001b[0m E_flat \u001b[38;5;241m=\u001b[39m E\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)                           \u001b[38;5;66;03m# [n_walkers * batch_size]\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Compute ∇θ log Ψ per sample\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "grads = get_gradients_walkers(reshaped_Xs, local_E, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02f4c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sampled_Xs[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1523678c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4499, 6])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b095aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network\n",
    "E = local_E\n",
    "x = sampled_Xs[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3077bd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4499, 6])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33406f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b8aafa5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4499])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_E[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21c21f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4499\n",
    "param_shapes = [p.shape for p in network.parameters()]\n",
    "n_params = sum(p.numel() for p in network.parameters())\n",
    "\n",
    "grads = torch.zeros(batch_size, n_params)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    xi = x[i].detach().clone().requires_grad_(True)\n",
    "\n",
    "    log_psi_i = network(xi).squeeze()\n",
    "    grad_i = torch.autograd.grad(\n",
    "        log_psi_i, \n",
    "        network.parameters(),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )\n",
    "\n",
    "# Flatten and concat all parameter gradients for this sample\n",
    "grad_i_flat = torch.cat([g.reshape(-1) for g in grad_i])\n",
    "grads[i] = grad_i_flat\n",
    "\n",
    "mean_grad_psi = torch.mean(grads)\n",
    "mean_E = torch.mean(E)\n",
    "\n",
    "part_a = grads - mean_grad_psi\n",
    "part_b = E - mean_E\n",
    "\n",
    "t = torch.mean(part_a.T * part_b[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f458c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1313])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1927991f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4499, 1313])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f141e97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 4499])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac380b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1313, 4499])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf71942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
